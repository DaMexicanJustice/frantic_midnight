{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Installation guide:\n",
    "\n",
    "## Setup\n",
    "\n",
    "We need to setup a Python environment. There are many ways, but to follow along with our example we recommend a virtual machine running ubuntu. \n",
    "The following is a step by step guide to setting up a virtual machine Python enviroment and getting everything ready.\n",
    "\n",
    "### Necessary software\n",
    "The editor most of us use is called jupyter and the way to get into that editor is by doing the following:\n",
    "\n",
    "Get a Bash-like terminal terminal on Windows by installing Git Bash, which can be downloaded from the following link: https://git-scm.com/downloads.\n",
    "`git clone https://github.com/HelgeCPH/get_things_done_with_python` will cloneinto a new folder, which you do by opening git bash on the selected folder and write git clone.\n",
    "\n",
    "Next up, we need to handle virtualization. We recommend [Virtual Box](https://www.virtualbox.org/). Download, run and install.\n",
    "The cloned github repository from earlier contains a Vagrant file. In order to use it you need to get [Vagrant](https://www.vagrantup.com/). Download, run & install.\n",
    "If you did not get the Vagrant file from the repository, you can find it [here](https://pastebin.com/7XxNfvGZ).\n",
    "\n",
    "\n",
    "### Virtual Environment\n",
    "\n",
    "Navigate to the folder containing the cloned github project or the vagrant file you created using the pastebin. Open a terminal here (On Windows, right-click and GitBash here). Finally in the terminal type:\n",
    "vagrant up\n",
    "\n",
    "The first installation is heavy and expect it to take up towards an hour. It installs many useful libraries and programs on your Virtual Machine that we will end up using.\n",
    "On the other side of the installation type:\n",
    "`vagrant ssh`\n",
    "\n",
    "to remote connect to your new virtual enviroment. With a little luck, you should see a similar screen to this ![image](http://i66.tinypic.com/6h2uk9.png).\n",
    "\n",
    "Your environment is now ready, but let's work in a fitting directory, so use the cd command to navigate to:\n",
    "/python_course/notebooks\n",
    "once there type\n",
    "workon course\n",
    "and you are now ready to create a Python file in the directory and implement our solution.\n",
    "\n",
    "### Python file creation\n",
    "\n",
    "You can create a new Python file in various ways. You can open Jupyter in a browser and work from there or alternatively create one from the command line with:\n",
    "$ touch filename.py\n",
    "we recommend Jupyter:\n",
    "\n",
    "You direct to python_course/notebook.\n",
    " e e\n",
    "From the `/python_course/notebooks` directory you should run the command `jupyter notebook --no-browser --ip=0.0.0.0 --NotebookApp.token=''` to start the Jupyter server.\n",
    "Accessible by opening any browser outside your Virtual Machine and connecting to 127:0:0.8884\n",
    "\n",
    "Notice that opening a Jupyter server will reserve the ssh connection, which then will be needed to be closed and opened everytime you wish to navigate the terminal. Done by pressing:\n",
    "ctrl + c and then Y and enter. Alternatively run a second terminal and vagrant ssh from there to have both. \n",
    "\n",
    "# Task\n",
    "\n",
    "Your task is to reproduce their results. That is, check out the code, make the examples run. Subsequently, modify the neural network to use a different amount of perceptrons in the hidden layer, add another hidden layer, switch to another activation function and see how each of your changes affects the amount of correctly/wrongly classified digits.\n",
    "\n",
    "# Files\n",
    "In order to start working on the mnist example we need to clone the necessary files located at:\n",
    "(Martin Gorner)[https://github.com/martin-gorner/tensorflow-mnist-tutorial.git]\n",
    "\n",
    "Make sure to clone the project or move the cloned project into the directory: /python_course/notebooks/programs/mnist or simply /mnist without the programs directory if you please\n",
    "\n",
    "# Program\n",
    "\n",
    "## First run\n",
    "Access the terminal on your virtual machine and run the Python file mnist_1.0_softmax.py (from the correct directory, see above)\n",
    "\n",
    "If your virtualization works correctly, you should see something similar to this:\n",
    "![image](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/ff7a33de1f55fba8.png)\n",
    "\n",
    "If not, disable the visualization by going into the python file and edited the lines:\n",
    "\n",
    "Comment / uncomment the lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#datavis.animate(training_step, iterations=2000+1, train_data_update_freq=10, test_data_update_freq=50, more_tests_at_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(2000+1): training_step(i, i % 50 == 0, i % 10 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or attempt to upgrade your installation of these by typing in your terminal:\n",
    "\n",
    "`sudo -H pip3 install --upgrade tensorflow`\n",
    "\n",
    "`sudo -H pip3 install --upgrade matplotlib`\n",
    "\n",
    "Running the program now should yield a result similar to this:\n",
    "![image](./first_run_accuracy.PNG)\n",
    "\n",
    "## Question 1\n",
    "\n",
    "The above screenshot also serves as the first observation we can make. Running the digit recognition with a neural network of 1 layer (with 10 neurons) yields an accuracy of 0.9219%\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Let us try to add an additional layer to our neural network. We do that by adding the following lines to mist_1.0_softmax.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO ADD AN ADDITIONAL NEURON LAYER WE NEED TO PREPARE AN ADDITIONAL WEIGHTS MATRIX AN BIASES VECTOR\n",
    "W1 = tf.Variable(tf.truncated_normal([28*28, 200] ,stddev=0.1))\n",
    "B1 = tf.Variable(tf.zeros([200]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# flatten the images into a single line of pixels\n",
    "# -1 in the shape definition means \"the only possible dimension that will preserve the number of elements\"\n",
    "#XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "## USING MULTIPLE LAYERS INSTEAD. 2 LAYERS THIS TIME\n",
    "XX = tf.reshape(X, [-1, 28*28])\n",
    "\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)\n",
    "Y  = tf.nn.softmax(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's run the file and observe the results\n",
    "![image](./2_layers_accuracy.PNG)\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Next up, let's try changing the number of neurons and only 1 layer in our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question 4\n",
    "\n",
    "### Single layer\n",
    "\n",
    "Let's observe what happens if we change the activation function from softmax (single layer neural network of 10 neurons) to hyperbolic tangent\n",
    "![image](./tanh_accuracy.PNG)\n",
    "changing the activation function to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = tf.nn.tanh(tf.matmul(XX, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what if we change from hyperbolic tangent to sigmoid but with a single layer instead of two\n",
    "![image](./sigmoid_accuracy.png)\n",
    "\n",
    "Using the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = tf.nn.sigmoid(tf.matmul(XX, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in conclusion, for a neural network with a single layer the softmax activation function yields the highest accuracy. But what about for a neural network with 2 layers?\n",
    "\n",
    "### Two-layers\n",
    "\n",
    "We will try and swap the sigmoid activation function in our neural network with two layers with a less problematic one called [relu](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#7). \n",
    "\n",
    "Change the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1 = tf.nn.relu(tf.matmul(XX, W1) + B1) #instead of using sigmoid()\n",
    "Y  = tf.nn.softmax(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then observe the results\n",
    "![image](./relu_accuracy.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
